---
title: "Regression Feature Selection Wrapper: GLMNET w/ WCFD data"
author: "Scott McKean"
output:
  pdf_document: default
  html_document: default
---

# Geoscience BC Study Code - Machine Learning Wrapper

```{r setup, include=FALSE}
library(geosciencebc2019008)
run_date = Sys.Date() %>% str_replace_all(., "-", "_")

model_prefix = 'glm_bcogc'
input_file = "../output/bcogc_mldf.rds"
```

## ML Dataframe Prep

This chunk prepares our dataframe for clustering, statistical modelling, and other data science techniques. It specifies auxillary columns (those useful for information), predictor columns, and our target column(s): seimogenic (T/F) and max magnitude (numeric).

For the regression problem, we focus exclusively on wells that have generated earthquakes. The dataset is therefore quite a bit smaller, but non-seismogenic wells provide no information regarding the maximum magnitude of earthquake generated by an event.

```{r}
target = "max_mag"

regr_comp_feats  = c(
  "calc_total_fluid_m3", "calc_total_proppant_t", "calc_completed_length_m",
  "n_stages", "min_midpoint_dist"
  )

regr_geo_feats = c(
  "pressure_depth_ratio_kpa_m", "top_montney_structure_mss", "third_order_residual_m",
  "geothermal_gradient_degc_km", "distance_listric_faults_berger_m",
  "distance_normal_faults_berger_m"
  )

final_feats = c(regr_comp_feats, regr_geo_feats)

ml_df <- read_rds(input_file) %>%
  dplyr::filter(seismogenic == 1) %>%
  dplyr::select(all_of(target), all_of(final_feats))

set.seed(2019008)
train_rows = sample(nrow(ml_df)*0.9)

train = ml_df[train_rows,]
test = ml_df[-train_rows,]
```

## Final Model Tuning

```{r}
learner = makeLearner("regr.glmnet")

train_task = makeRegrTask(data = train, target = target)
test_task = makeRegrTask(data = test, target = target)
all_task = makeRegrTask(data = ml_df, target = target)
meas = list(mae, rmse)

# hyperparameter tuning with 5-fold cross-validation & MBO optimization
pset= makeParamSet(
  makeNumericParam('alpha',lower = 0, upper = 1),
  makeIntegerParam('lambda', lower = -4, upper = 1, trafo = function(x) 10^x)
)

tune_res = tuneParams(
  learner, train_task, resampling=cv5, par.set=pset, 
  control=makeTuneControlMBO(budget = 30L),
  measures=meas
)

write_rds(tune_res, paste0('../output/',model_prefix,"_tune_res.rds"))

# set hyperparameters
tuned_learner = setHyperPars(learner = learner, par.vals = tune_res$x)

# train final model for performance and interpretation
model = train(tuned_learner, train_task)
test_predict = predict(model, newdata=test)
performance(test_predict, measures = meas)

train_predict = predict(model, newdata=train)
performance(train_predict, measures = meas)

predictor = Predictor$new(model, data = ml_df)

# monte-carlo performance measures
resample = mlr::resample(
  tuned_learner, all_task, 
  makeResampleDesc("Subsample", iters=100, split=4/5, predict='both'),  
  measures = meas,
  show.info = FALSE
  )

resample_res = get_resample_regr_res(resample)
print(resample_res)

write_rds(resample_res, paste0('../output/',model_prefix,"_resample.rds"))
```

## Residual Analysis

```{r}
p1 = plotResiduals(train_predict) +
  geom_abline(slope=1,linetype = "dashed") +
  ggtitle("Training Set") +
  theme_minimal()

p2 = plotResiduals(test_predict) +
  geom_abline(slope=1,linetype = "dashed") +
  ggtitle("Test Set") +
  theme_minimal()

ggsave(file = paste0('../output/',model_prefix,"_resplot.jpg"), 
       arrangeGrob(grobs = list(p1,p2), nrow=1),
       width = 12, height = 8)
```

## Prediction Plots

```{r}

p1 = plotLearnerPrediction(
  tuned_learner, task = all_task, 
  features = c("calc_total_fluid_m3", "calc_total_proppant_t"),
  measures = mae
  )

p2 = plotLearnerPrediction(
  tuned_learner, task = all_task, 
  features = c("min_midpoint_dist", "n_stages"),
  measures = mae
  )

p3 = plotLearnerPrediction(
  tuned_learner, task = all_task, 
  features = c("third_order_residual_m", "geothermal_gradient_degc_km"),
  measures = mae
  )

p4 = plotLearnerPrediction(
  tuned_learner, task = all_task, 
  features = c("distance_listric_faults_berger_m", "distance_normal_faults_berger_m"),
  measures = mae
  )

ggsave(file = paste0('../output/',model_prefix,"_learnpreds.jpg"), 
       arrangeGrob(grobs = list(p1,p2,p3,p4), nrow=2),
       width = 12, height = 8)
```

## Feature Importance and Interaction

```{r}
# importance plot
imp = FeatureImp$new(predictor, loss='mae')

p1 = ggplot(imp$results) +
  geom_col(aes(x = feature, y = importance)) +
  labs(x = 'Feature', y = 'Permutation Importance') +
  coord_flip() +
  theme_minimal()

interact = Interaction$new(predictor)

p2 = ggplot(as.data.frame(interact$results)) +
  geom_col(aes(x = .feature, y = .interaction)) +
  labs(x = '', y = 'Interaction') +
  coord_flip() +
  theme_minimal()

ggsave(file = paste0('../output/',model_prefix,"_impintplot.jpg"), 
       arrangeGrob(grobs = list(p1,p2), nrow=1),
       width = 12, height = 8)
```

## Partial Dependence & ICE Plots

```{r }        
   # partial dependence plot
make_pdp_plot <- function(i, predictor, feats){
  pdp <- FeatureEffect$new(predictor, method = 'pdp+ice', 
                           feature = feats[i], center.at = 2)
  
  plot(pdp) + theme_minimal() + theme(axis.title.y=element_blank())
}

plist <- map(.x = 1:length(final_feats), .f = make_pdp_plot,
             predictor = predictor, feats = final_feats)

ggsave(file = paste0('../output/',model_prefix,"_pdpplot.jpg"), 
       arrangeGrob(grobs = plist, ncol = 3, left = 'Magnitude'),
       width = 12, height = 8)

```

## LIME & SHAP

```{r}
shap_wells = c(123, 255)

for (well in shap_wells){
  lime.explain = LocalModel$new(predictor, 
                                x.interest = ml_df[well,],
                                k = length(final_feats))
  
  p1 = ggplot(lime.explain$results) +
    geom_col(aes(x = feature, y = effect)) +
    labs(x = 'Feature', y = 'LIME Effect') +
    coord_flip() +
    theme_minimal()
  
  shapley = Shapley$new(predictor,
                        x.interest = ml_df[well,] %>% 
                          dplyr::select(all_of(final_feats)),
                        sample.size = 100)
  
  p2 = ggplot(shapley$results) +
    geom_col(aes(x = feature, y = phi)) +
    labs(x = 'Feature', y = 'SHAP Phi') +
    coord_flip() +
    theme_minimal()
  
  ggsave(file = paste0('../output/',model_prefix,"_",well,"_limeshap.jpg"),
         arrangeGrob(grobs = list(p1,p2), nrow=1),
         width = 12, height = 4)
}
```